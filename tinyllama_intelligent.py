#!/usr/bin/env python3
"""
TinyLlama + MCPÂ v0.4.1
=====================
â€¢ Mejora `_prettify_chunk` para manejar cadenas que contienen **listas de dicts
  representadas con comillas simples** (el caso que aparecÃ­a como:
  `Autores de chile: [{'id': 2, 'nombre': 'Isabelâ€¦'}, â€¦]`).
â€¢ Si detecta ese patrÃ³n, convierte con `ast.literal_eval` y redacta frase
  amigable.
"""

import os
import json
import re
import ast
from textwrap import shorten
from typing import List, Optional

import requests

try:
    from llama_cpp import Llama  # type: ignore
    LLAMA_CPP_AVAILABLE = True
except ImportError:
    LLAMA_CPP_AVAILABLE = False
    print("âš ï¸  llamaâ€‘cppâ€‘python no estÃ¡ instalado. Se usarÃ¡ modo heurÃ­stico.")

MCP_ENDPOINTS = [
    os.getenv("MCP_BIBLIOTECA", "http://127.0.0.1:8100"),
    os.getenv("MCP_COMPRAS", "http://127.0.0.1:8200"),
]

MCP_BIBLIOTECA = os.getenv("MCP_BIBLIOTECA", "http://127.0.0.1:8100")
MCP_COMPRAS = os.getenv("MCP_COMPRAS", "http://127.0.0.1:8200")

MAX_CHUNK_CHARS = 2_000

# -------------------------------------------------------------
# Utilidades de formato Â«naturalÂ» cuando no hay modelo
# -------------------------------------------------------------

def _format_list_of_dicts(lst: List[dict]) -> str:
    if not lst:
        return "(sin resultados)"
    if "titulo" in lst[0]:
        titulos = ", ".join(d.get("titulo", "Â¿?") for d in lst[:5])
        extra = "â€¦" if len(lst) > 5 else ""
        return f"Se encontraron {len(lst)} libro(s): {titulos}{extra}."
    if "nombre" in lst[0]:
        nombres = ", ".join(d.get("nombre", "Â¿?") for d in lst[:5])
        extra = "â€¦" if len(lst) > 5 else ""
        return f"Autores: {nombres}{extra}."
    return ", ".join(str(d) for d in lst)


def _prettify_chunk(text: str) -> str:
    """Convierte la mayorÃ­a de textos devueltos por MCP en frases legibles."""
    # 1) Â¿Es JSON vÃ¡lido?
    try:
        data = json.loads(text)
        if isinstance(data, list):
            return _format_list_of_dicts(data)
        if isinstance(data, dict):
            if {"total_autores", "total_libros"}.issubset(data.keys()):
                return (
                    f"La biblioteca cuenta con {data['total_autores']} autores y "
                    f"{data['total_libros']} libros (publicados entre "
                    f"{data['rango_aÃ±os_publicacion']['aÃ±o_mas_antiguo']} y "
                    f"{data['rango_aÃ±os_publicacion']['aÃ±o_mas_reciente']})."
                )
            if "nombre" in data:
                return f"Autor: {data['nombre']} ({data.get('nacionalidad','?')})."
            if "titulo" in data:
                return f"Libro: â€œ{data['titulo']}â€ ({data.get('anio_publicacion','?')})."
    except Exception:
        pass

    # 2) Detecta patrÃ³n "Texto: [ { â€¦ } , â€¦ ]" con comillas simples
    m = re.search(r":\s*(\[\{.*\}\])", text)
    if m:
        try:
            py_obj = ast.literal_eval(m.group(1))  # convierte a lista de dicts
            return _format_list_of_dicts(py_obj)
        except Exception:
            pass

    # 3) Detecta lista de dicts sin prefijo
    if text.strip().startswith("[") and text.strip().endswith("]"):
        try:
            py_obj = ast.literal_eval(text)
            if isinstance(py_obj, list):
                return _format_list_of_dicts(py_obj)
        except Exception:
            pass

    # 4) Limpieza ligera de listas de strings entre comillas
    text = re.sub(r"\['([^']+)'(?:, '([^']+)')*\]", lambda m: m.group(0).replace("[","").replace("]","").replace("'",""), text)
    pretty = text.strip()
    if pretty and not pretty.endswith(('.', 'â€¦', '"')):
        pretty += '.'
    return pretty

def _detect_domain(question: str) -> str:
        q_lower = question.lower()
        if any(palabra in q_lower for palabra in ["cliente", "clientes", "compra", "compras", "producto", "productos", "stock", "precio", "paÃ­s"]):
            return "compras"
        if any(palabra in q_lower for palabra in ["libro", "libros", "autor", "autores", "editorial", "nacionalidad", "publicaciÃ³n"]):
            return "biblioteca"
        return "desconocido"
# -------------------------------------------------------------
# Host principal (sin cambios en la lÃ³gica)
# -------------------------------------------------------------
class IntelligentTinyLlama:
    def __init__(self, model_path: Optional[str] = None):
        self.model = None
        if LLAMA_CPP_AVAILABLE and model_path:
            try:
                print("ğŸ¦™ Cargando TinyLlama â€¦")
                self.model = Llama(model_path=model_path, n_ctx=4096, n_threads=4, verbose=False)
                print("âœ… TinyLlama cargado")
            except Exception as exc:
                print(f"âŒ No se pudo cargar el modelo: {exc}")

    @staticmethod
    def _call_mcp(question: str) -> List[str]:
        domain = _detect_domain(question)
        base_url = {
            "biblioteca": MCP_BIBLIOTECA,
            "compras": MCP_COMPRAS
        }.get(domain)

        if not base_url:
            print("âš ï¸  No se pudo determinar el dominio de la pregunta.")
            return []

        try:
            r = requests.post(f"{base_url}/provision", json={"query": question}, timeout=10)
            r.raise_for_status()
            return [c.get("text", "") for c in r.json().get("chunks", [])]
        except Exception as exc:
            print(f"âš ï¸  Error llamando al MCP ({domain}) en {base_url}:", exc)
            return []

    def answer_question(self, question: str) -> str:
        chunks = self._call_mcp(question)
        print(f"ğŸŒ Dominio detectado: {_detect_domain(question)}")
        context_text = "\n".join(shorten(c, MAX_CHUNK_CHARS) for c in chunks)

        if self.model:
            prompt = (
                "### Contexto:\n" + context_text +
                "\n\n### Pregunta:\n" + question +
                "\n\n### Responde en espaÃ±ol natural, claro y conciso:\n"
            )
            out = self.model(prompt, max_tokens=320, temperature=0.6, stop=["###"])
            return out["choices"][0]["text"].strip()

        if not chunks:
            return "Lo siento, no encontrÃ© informaciÃ³n para tu pregunta."

        if len(chunks) == 1:
            return _prettify_chunk(chunks[0])

        partes = ["AquÃ­ tienes la informaciÃ³n relevante:"]
        for idx, ch in enumerate(chunks, 1):
            partes.append(f"{idx}. {_prettify_chunk(ch)}")
        return "\n".join(partes)

# -------------------------------------------------------------
# CLI (igual que antes)
# -------------------------------------------------------------

def main():
    print("ğŸ§  TinyLlama + MCP mÃºltiple")
    print("=" * 60)

    for base_url in MCP_ENDPOINTS:
        try:
            r = requests.get(f"{base_url}/manifest", timeout=5)
            r.raise_for_status()
            name = r.json().get("name", "Â¿?")
            print(f"âœ… MCPâ€‘Server conectado en {base_url} â†’ {name}")
        except Exception as exc:
            print(f"âŒ No se pudo acceder al MCP en {base_url}:", exc)

    model_path = "./TinyLlama-1.1B-Chat-v1.0-GGUF/tinyllama-1.1b-chat-v1.0.Q8_0.gguf"
    bot = IntelligentTinyLlama(model_path if os.path.exists(model_path) else None)

    print("\nEscribe 'salir' para terminar.\n")
    while True:
        try:
            q = input("ğŸ‘¤ Pregunta: ").strip()
            if q.lower() in {"salir", "exit", "quit"}:
                break
            if q:
                print("ğŸ¤” Buscando â€¦")
                ans = bot.answer_question(q)
                print("\nğŸ“– " + ans + "\n")
                print("-" * 60)
        except KeyboardInterrupt:
            break
        except Exception as exc:
            print("âŒ Error inesperado:", exc)

    print("\nğŸ‘‹ Hasta luego")


if __name__ == "__main__":
    main()
